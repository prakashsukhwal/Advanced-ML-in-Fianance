{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"2. Loss Functions.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"crucial-warner"},"source":["#### Author: Prakash C. Sukhwal\n","#### July 2021\n","#### Associated Lecturer & Consultant\n","#### Institute of Systems Science, NUS\n","\n","---"],"id":"crucial-warner"},{"cell_type":"code","metadata":{"id":"welcome-cotton"},"source":["## turn on the autocomplete if off by default\n","%config use_jedi = False"],"id":"welcome-cotton","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"preliminary-maldives"},"source":["###### All the given implementations are in pytorch version: 1.7.1\n","- to check you version type the below commands in your notebook\n","      - import torch\n","      - torch.__version__"],"id":"preliminary-maldives"},{"cell_type":"code","metadata":{"id":"static-working"},"source":["import torch\n","import torch.nn as nn"],"id":"static-working","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rf_wGUC5aFaO","executionInfo":{"status":"ok","timestamp":1621863035229,"user_tz":-480,"elapsed":346,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"de9b0f56-a0af-494d-d474-dd6b95a5f163"},"source":["# check the version\n","torch.__version__"],"id":"rf_wGUC5aFaO","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.8.1+cu101'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"senior-zoning"},"source":["##### 1. MAE: Mean Absolute Error or L1 Loss"],"id":"senior-zoning"},{"cell_type":"markdown","metadata":{"id":"precise-abraham"},"source":["<img src=\"https://drive.google.com/uc?id=1swk0KoIIFKH6LUgza_DKw_nC1nEuzE9V\" alt=\"image\" \n","    width=\"400\" \n","    height=\"180\" class=\"center\">\n","    "],"id":"precise-abraham"},{"cell_type":"markdown","metadata":{"id":"positive-banks"},"source":["    Note:\n","    - less affected by outliers\n","    - when we use minibatch n is the batch size else n is all the samples"],"id":"positive-banks"},{"cell_type":"markdown","metadata":{"id":"negative-centre"},"source":["###### how to invoke it in torch?\n","       - we invoke it from class torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n","       - reduction (string, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. \n","        'none': no reduction will be applied, \n","        'mean': the sum of the output will be divided by the number of elements in the output, \n","        'sum': the output will be summed. \n","         Default: 'mean'\n","source: https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss"],"id":"negative-centre"},{"cell_type":"code","metadata":{"id":"after-basics"},"source":["## let us say you want to get the loss between two tensors pred and act where \n","## pred: predicted target values and act: actual target values\n","\n","loss = nn.L1Loss()\n","pred = torch.randn(3, 5, requires_grad= True)\n","act = torch.randn(3, 5)\n","err = loss(pred, act)\n","err.backward()"],"id":"after-basics","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exceptional-enlargement"},"source":[""],"id":"exceptional-enlargement","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"expanded-tournament"},"source":["##### 2. MSE: Mean Square Error or L2 Loss"],"id":"expanded-tournament"},{"cell_type":"markdown","metadata":{"id":"infectious-relaxation"},"source":["<img src=\"https://drive.google.com/uc?id=1aNtxU25D0CzDByxSMY2xdZ3UeMrEtYm_\" alt=\"image\" \n","    width=\"400\" \n","    height=\"180\" class=\"center\">"],"id":"infectious-relaxation"},{"cell_type":"markdown","metadata":{"id":"altered-camcorder"},"source":["    Note:\n","    - impact of outliers is more pronounced in MSE than MAE\n","    - when we use minibatch n is the batch size else n is all the samples"],"id":"altered-camcorder"},{"cell_type":"markdown","metadata":{"id":"varied-pleasure"},"source":["###### how to invoke it in torch?\n","\n","    - we invole it from class torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n","    - reduction (string, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. \n","    'none': no reduction will be applied, \n","    'mean': the sum of the output will be divided by the number of elements in the output, \n","    'sum': the output will be summed. \n","     Default: 'mean'\n","source: https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss"],"id":"varied-pleasure"},{"cell_type":"code","metadata":{"id":"alien-productivity"},"source":["## let us say you want to get the loss between two tensors pred and act where \n","## pred: predicted target values and act: actual target values\n","\n","loss = nn.MSELoss(reduction='none')\n","#print(loss)"],"id":"alien-productivity","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moving-antigua","executionInfo":{"status":"ok","timestamp":1621863314578,"user_tz":-480,"elapsed":4,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"f8b17b7a-21ba-4825-9af0-4bf8189406ce"},"source":["# create random pred and act\n","pred = torch.randn(3, 5)\n","print(pred)\n","act = torch.randn(3, 5)\n","print(act)\n","\n","\n","err = loss(pred, act)\n","print('error \\n')\n","print(err)\n","\n","print(pred.grad)"],"id":"moving-antigua","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0463,  0.3386,  0.5060,  0.3870, -0.3964],\n","        [ 0.6855, -0.8004,  1.0951,  0.1720, -0.3706],\n","        [ 0.3975,  1.0624,  2.9286, -0.6500,  0.0071]])\n","tensor([[ 1.2731,  1.1445,  2.0540,  0.3410, -1.0231],\n","        [ 0.7668, -0.0611, -0.6694, -0.1932,  0.3795],\n","        [-1.5548, -0.1715, -0.9569, -0.1222,  1.1381]])\n","error \n","\n","tensor([[1.5049e+00, 6.4943e-01, 2.3963e+00, 2.1160e-03, 3.9278e-01],\n","        [6.6242e-03, 5.4645e-01, 3.1135e+00, 1.3332e-01, 5.6261e-01],\n","        [3.8116e+00, 1.5224e+00, 1.5098e+01, 2.7849e-01, 1.2792e+00]])\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ultimate-difference"},"source":["    Note:\n","        - backpropagation is handled by variables and not nn.Module"],"id":"ultimate-difference"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"local-shaft","executionInfo":{"status":"ok","timestamp":1621863331589,"user_tz":-480,"elapsed":819,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"d367cc1b-012f-4518-c36f-f1271223867a"},"source":["# compute with backpropagation\n","pred = torch.randn(3, 5, requires_grad= True)\n","act = torch.randn(3, 5)\n","\n","err = loss(pred, act)\n","print('error \\n')\n","print(err)\n","\n","print(pred.grad)"],"id":"local-shaft","execution_count":null,"outputs":[{"output_type":"stream","text":["error \n","\n","tensor([[1.0710e+01, 9.2594e-01, 3.9583e-01, 3.9658e+00, 3.2851e+00],\n","        [9.8965e-03, 7.7764e-01, 5.1768e-01, 4.2635e+00, 6.3811e+00],\n","        [8.2533e-04, 5.2075e-01, 6.4039e+00, 2.7051e+00, 9.8436e+00]],\n","       grad_fn=<MseLossBackward>)\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOwR1hygj0RV","executionInfo":{"status":"ok","timestamp":1621863336381,"user_tz":-480,"elapsed":302,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"c1b2a0e3-4d8e-4b24-c201-b74407047928"},"source":["# with reduction\n","loss = nn.MSELoss(reduction= 'mean')\n","# compute with backpropagation\n","pred = torch.randn(3, 5, requires_grad= True)\n","act = torch.randn(3, 5)\n","\n","err = loss(pred, act)\n","\n","print(err)\n","\n","print(pred.grad)"],"id":"QOwR1hygj0RV","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(1.3740, grad_fn=<MseLossBackward>)\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"authorized-bridal"},"source":["###### Question: How do you get RMSE from the MSE?\n"],"id":"authorized-bridal"},{"cell_type":"code","metadata":{"id":"lasting-causing"},"source":["class RMSELoss(nn.Module):\n","    def __init__(self, eps=1e-6):\n","        super().__init__()\n","        self.mse = nn.MSELoss()\n","        self.eps = eps\n","    def forward(self, pred, act):\n","        loss = torch.sqrt(self.mse(pred, act)+ self.eps)\n","        return loss"],"id":"lasting-causing","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"removed-planet"},"source":["mse=0 will cause issue for the gradient during backward pass as a result of multiplying 0 by derivative of 0 which is infinity. \n","So you see eps added above"],"id":"removed-planet"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"streaming-incident","executionInfo":{"status":"ok","timestamp":1620702731002,"user_tz":-480,"elapsed":740,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"2859b31c-19d8-4190-c9e4-10d1f5ca603b"},"source":["rmse = RMSELoss()\n","\n","rmse_loss = rmse(pred, act)\n","\n","print(rmse_loss.backward())\n","\n","print(pred.grad)"],"id":"streaming-incident","execution_count":null,"outputs":[{"output_type":"stream","text":["None\n","tensor([[-0.2314, -0.4303, -0.1116, -0.5244,  0.1890],\n","        [ 0.0233, -0.1346,  0.3256,  0.3586,  0.0416],\n","        [-0.2692, -0.1448,  0.2487,  0.3116,  0.1140]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"metallic-douglas"},"source":["###### Question: above we see formula for one neuron output; How to incorporate errors from more than one neuron?"],"id":"metallic-douglas"},{"cell_type":"markdown","metadata":{"id":"visible-syracuse"},"source":["    we sum-up the errors from all the neurons"],"id":"visible-syracuse"},{"cell_type":"markdown","metadata":{"id":"infectious-thomas"},"source":["###### Question: Can you combine L1 and L2 losses?"],"id":"infectious-thomas"},{"cell_type":"markdown","metadata":{"id":"recent-scholar"},"source":["    Yes, it is called smooth L1 loss or Huber loss"],"id":"recent-scholar"},{"cell_type":"code","metadata":{"id":"excited-lafayette"},"source":[""],"id":"excited-lafayette","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"consistent-church"},"source":["##### 3. Binary Cross Entropy Loss or Log Loss"],"id":"consistent-church"},{"cell_type":"markdown","metadata":{"id":"forbidden-hughes"},"source":["<img src=\"https://drive.google.com/uc?id=11-rib5RXvdzMa2yUr2_LpV0Wuozi6act\" alt=\"image\" \n","    width=\"600\" \n","    height=\"400\" class=\"center\">\n","    \n","source: https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html\n","\n","    Note: \n","        - we sum over all the samples (1 to N) and divide by -(1/N) to get overall error"],"id":"forbidden-hughes"},{"cell_type":"markdown","metadata":{"id":"altered-millennium"},"source":["    Entropy: tells us about the uncertainty involved with certain probability distribution. Eg. you need 3 bits to represent 8 different animals given by log2(8) [binary encoding scheme] and for 1024 animals it is 10. More variation in probability means more entropy.\n","    \n","    Cross-Entrpy: number of bits required to explain the difference between 2 probability distributions"],"id":"altered-millennium"},{"cell_type":"markdown","metadata":{"id":"modular-vocabulary"},"source":[" ###### how to invoke it in torch?\n","\n","    - we invole it from class torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n","    - reduction (string, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. \n","    'none': no reduction will be applied, \n","    'mean': the sum of the output will be divided by the number of elements in the output, \n","    'sum': the output will be summed. \n","     Default: 'mean'\n","source: https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss"],"id":"modular-vocabulary"},{"cell_type":"code","metadata":{"id":"industrial-collective"},"source":["m = nn.Sigmoid() # activation function\n","loss = nn.BCELoss()"],"id":"industrial-collective","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"touched-dependence","executionInfo":{"status":"ok","timestamp":1620702743510,"user_tz":-480,"elapsed":560,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"27672584-ff78-4213-8fa4-d3bf7e38d260"},"source":["pred = torch.randn(3, requires_grad=True)\n","print(pred)\n","act = torch.empty(3).random_(2)\n","print(act)"],"id":"touched-dependence","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([ 1.4958, -1.8144, -0.4815], requires_grad=True)\n","tensor([0., 0., 1.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"historic-computer"},"source":["err = loss(m(pred), act)\n","err.backward()"],"id":"historic-computer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"southeast-intranet"},"source":["###### Question: In a distribution where target is set of classes {cat (1), dog (0)} and both classes are equally distruted.\n","    1. is the entropy very low or very high?\n","    2. what is the binary cross entropy in this case?"],"id":"southeast-intranet"},{"cell_type":"markdown","metadata":{"id":"governmental-potter"},"source":["    1. highest for equal distribution\n","    2. -(1*(log(0.5)) + (1-1)* (log(1-0.5))) => log(2)"],"id":"governmental-potter"},{"cell_type":"markdown","metadata":{"id":"downtown-powell"},"source":["###### Question: In a multi-class emotion detection exercise (where more than one label can be correct) where a person is both happy and energetic in reality we got the below output probabilities in a NN. Assuming only one sample (N=1), compute the binary cross entropy loss\n","\n","    pred = [0.2, 0.8, 0.2, 0.4]\n","    act = [sad, happy, energetic, scared]"],"id":"downtown-powell"},{"cell_type":"markdown","metadata":{"id":"developed-understanding"},"source":["    bce = (-1/1)* [(1-0)*log(1- 0.2) + 1*log(0.8) + 1*log(0.2) + (1-0)*log(1-0.4)]\n","        = - [-0.09  + (-0.09) + (-0.69) + (-0.22)]\n","    note: when the network makes error and leans towards wrong labels (i.e., high predicted prob. for a wrong label) we see high magnitude of individual error."],"id":"developed-understanding"},{"cell_type":"code","metadata":{"id":"constitutional-makeup"},"source":[""],"id":"constitutional-makeup","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"seasonal-element"},"source":["##### 4. Cross Entropy Loss or Log Loss"],"id":"seasonal-element"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boring-competition","executionInfo":{"status":"ok","timestamp":1620702762780,"user_tz":-480,"elapsed":952,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"e32ef0d1-1873-49fd-f891-487d4c437492"},"source":["loss = nn.CrossEntropyLoss()\n","pred = torch.randn(3, 5, requires_grad=True)\n","print(pred)\n","\n","act = torch.empty(3, dtype=torch.long).random_(5)# note: 1-D\n","print(act)\n","\n","err = loss(pred, act)\n","err.backward()"],"id":"boring-competition","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[-0.3726,  0.2790, -1.1045,  1.5715, -1.9348],\n","        [ 1.2946,  0.6695, -1.2225, -3.9203,  1.0332],\n","        [ 1.2877,  1.1664, -0.4983, -1.2589,  0.0110]], requires_grad=True)\n","tensor([1, 3, 4])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"focal-stick"},"source":["    note:\n","        - cross entroy loss in pytorch invokes softmax activation function internally"],"id":"focal-stick"},{"cell_type":"code","metadata":{"id":"amateur-quarter"},"source":[""],"id":"amateur-quarter","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"informal-participant"},"source":["###### 5. Hinge Loss (max-margin loss)"],"id":"informal-participant"},{"cell_type":"markdown","metadata":{"id":"filled-woman"},"source":["<img src=\"https://drive.google.com/uc?id=1R9KG2V4UOah8PRQialYS3sh-0jupBtZe\" alt=\"image\" \n","    width=\"600\" \n","    height=\"400\" class=\"center\">\n","\n","<img src=\"https://drive.google.com/uc?id=11JLZBqZadIY0l3N5lbxYSZ9GgsZJOLg8\" alt=\"image\" \n","    width=\"400\" \n","    height=\"180\" class=\"center\">\n","            \n","    source: \n","    https://stats.stackexchange.com/questions/372999/confusion-on-hinge-loss-and-svm\n","    https://en.wikipedia.org/wiki/Hinge_loss"],"id":"filled-woman"},{"cell_type":"markdown","metadata":{"id":"approved-nomination"},"source":["    note:\n","        - it is used for classification problems such as SVMs\n","        - labels used are -1 and +1 for target\n","        - penalizes wrong predictions and predictions with less confidence in correct class based on a margin\n","        - works towards maximizing the score for the true class (i.e., true class to have score larger than false classes by a margin)"],"id":"approved-nomination"},{"cell_type":"markdown","metadata":{"id":"hungry-yield"},"source":["###### Question\n","    compute the cross-entropy loss and hinge loss as shown in the figure below usnig pytorch. The blue class is the true class in this case.\n","    \n","<img src=\"https://drive.google.com/uc?id=1sEuCwxpFZS4GmQiTpl4f9SGGwQU6ENmC\" alt=\"image\" \n","    width=\"600\" \n","    height=\"350\" class=\"center\">\n","source: https://cs231n.github.io/linear-classify/#loss-function"],"id":"hungry-yield"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grateful-scenario","executionInfo":{"status":"ok","timestamp":1620702824221,"user_tz":-480,"elapsed":931,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"dc62ddbe-13b3-43b3-edcd-13658aff2eb2"},"source":["## Let's try the values given in the figure above in pytorch\n","\n","lg_prob = [-2.85, 0.86, 0.28]\n","print(type(lg_prob))\n","\n","# convert to tensor\n","lg_prob_tens = torch.tensor(lg_prob)\n","print(type(lg_prob_tens))"],"id":"grateful-scenario","execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","<class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"charitable-server","executionInfo":{"status":"ok","timestamp":1620702825364,"user_tz":-480,"elapsed":751,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"5952987c-683e-4011-8630-99f758a06987"},"source":["## 1. Cross Entropy Loss\n","# use softmax \n","# instantiate \n","sft = nn.Softmax()\n","out_prob = sft(lg_prob_tens)\n","\n","print(out_prob)\n","\n","# final loss\n","-torch.log(out_prob)"],"id":"charitable-server","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0.0154, 0.6312, 0.3534])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor([4.1702, 0.4602, 1.0402])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fifth-interstate","executionInfo":{"status":"ok","timestamp":1620702829176,"user_tz":-480,"elapsed":718,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"ea8c795f-49f4-4680-8459-313526c36489"},"source":["## 2. Hinge Loss\n","target_tens = torch.tensor([-1, -1, 1])\n","print(type(target_tens))"],"id":"fifth-interstate","execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"functioning-national"},"source":["## try-1\n","def hinge(y_true, y_pred):\n","    zero = torch.Tensor([0]) \n","    out = torch.max(zero, 1 - y_true * y_pred)\n","    print(out)\n","    return torch.sum(out)"],"id":"functioning-national","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"native-flower","executionInfo":{"status":"ok","timestamp":1620702834624,"user_tz":-480,"elapsed":1041,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"7de03e36-6ffe-4a21-c59b-092acd4816b1"},"source":["hinge(lg_prob_tens, target_tens)"],"id":"native-flower","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0.0000, 1.8600, 0.7200])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(2.5800)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"transsexual-theater"},"source":["## try-2\n","class MyHingeLoss(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(MyHingeLoss, self).__init__()\n","\n","    def forward(self, output, target):\n","\n","        hinge_loss = 1 - torch.mul(output, target)\n","        hinge_loss[hinge_loss < 0] = 0\n","        return hinge_loss"],"id":"transsexual-theater","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"religious-match","executionInfo":{"status":"ok","timestamp":1620702839833,"user_tz":-480,"elapsed":938,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"a035ef6f-54f6-4cf8-aca2-0632719d65ba"},"source":["h_loss2 = MyHingeLoss()\n","\n","#final loss-\n","print(h_loss2(lg_prob_tens,target_tens))\n","sum(h_loss2(lg_prob_tens,target_tens))"],"id":"religious-match","execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0.0000, 1.8600, 0.7200])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(2.5800)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"driving-subcommittee"},"source":["## try-3\n","h_loss3 = nn.MultiLabelMarginLoss()"],"id":"driving-subcommittee","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vertical-vegetation","executionInfo":{"status":"ok","timestamp":1620702844266,"user_tz":-480,"elapsed":819,"user":{"displayName":"Prakash Sukhwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzzt-AFO-3NEhq84ctHbsx-kMXPFGJBKbkyLO4=s64","userId":"00923159090350613901"}},"outputId":"787e41c7-7cfd-4033-e85a-382d4ddb1ef4"},"source":["h_loss3(lg_prob_tens,target_tens)"],"id":"vertical-vegetation","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"statewide-colleague"},"source":[""],"id":"statewide-colleague","execution_count":null,"outputs":[]}]}